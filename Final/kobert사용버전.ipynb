{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 필요한 라이브러리 설치\n",
    "- 먼저, 필요한 라이브러리를 설치합니다. 이 셀을 실행하여 transformers, torch, sentencepiece 등을 설치하세요.\n",
    "- !pip install transformers torch sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 중인 장치: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, BartForConditionalGeneration, AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# 장치 설정 (GPU 사용 가능 시 GPU, 아니면 CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"사용 중인 장치: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [\n",
    "    {\"input\": \"배가 고픈데 뭐 먹을까?\", \"output\": \"한식은 어때요? 따뜻한 국밥이 좋을 것 같아요.\"},\n",
    "    {\"input\": \"점심 추천해줘\", \"output\": \"가벼운 샐러드나 샌드위치는 어떠세요?\"},\n",
    "    {\"input\": \"저녁 뭐 먹을지 고민돼\", \"output\": \"맛있는 파스타나 스테이크는 어떠신가요?\"},\n",
    "    {\"input\": \"달콤한 디저트 먹고 싶어\", \"output\": \"초콜릿 케이크나 아이스크림을 추천드려요.\"},\n",
    "    {\"input\": \"시원한 거 마시고 싶어\", \"output\": \"아이스 아메리카노나 레몬 에이드를 드셔보세요.\"},\n",
    "    {\"input\": \"매운 음식이 땡겨\", \"output\": \"매운 떡볶이나 불닭볶음면은 어떠세요?\"},\n",
    "    {\"input\": \"간단하게 먹을 거 없어?\", \"output\": \"김밥이나 샌드위치를 드셔보세요.\"},\n",
    "    {\"input\": \"한국 전통 음식 추천해줘\", \"output\": \"비빔밥이나 불고기를 추천합니다.\"},\n",
    "    {\"input\": \"중국 음식이 먹고 싶어\", \"output\": \"짜장면이나 탕수육은 어떠세요?\"},\n",
    "    {\"input\": \"일식 좋아해\", \"output\": \"스시나 우동을 드셔보세요.\"},\n",
    "    {\"input\": \"양식 먹고 싶어\", \"output\": \"스테이크나 피자를 추천합니다.\"},\n",
    "    {\"input\": \"채식주의자야\", \"output\": \"채소 샐러드나 두부 요리를 드셔보세요.\"},\n",
    "    {\"input\": \"디저트 카페 추천해줘\", \"output\": \"근처에 있는 베이커리 카페는 어떠세요?\"},\n",
    "    {\"input\": \"건강식이 필요해\", \"output\": \"현미밥과 야채로 구성된 식단을 추천합니다.\"},\n",
    "    {\"input\": \"해산물 요리 먹고 싶어\", \"output\": \"회나 해물파전은 어떠세요?\"},\n",
    "    {\"input\": \"친구들이랑 먹을 거 추천해줘\", \"output\": \"치킨이나 피자를 시켜 드세요.\"},\n",
    "    {\"input\": \"새로운 맛집 없어?\", \"output\": \"요즘 핫한 수제 버거 가게를 추천합니다.\"},\n",
    "    {\"input\": \"간식 추천해줘\", \"output\": \"과일이나 요거트를 추천드립니다.\"},\n",
    "    {\"input\": \"더운 날씨에 뭐 먹지?\", \"output\": \"시원한 냉면이나 팥빙수를 드셔보세요.\"},\n",
    "    {\"input\": \"감기 걸렸어\", \"output\": \"따뜻한 죽이나 수프를 드시는 게 좋겠어요.\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "c:\\ProgramData\\anaconda3\\envs\\gnn_snn_torch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"gogamza/kobart-base-v2\",\n",
    "    bos_token='</s>',\n",
    "    eos_token='</s>',\n",
    "    unk_token='<unk>',\n",
    "    pad_token='<pad>'\n",
    ")\n",
    "\n",
    "# pad_token이 eos_token과 동일한지 확인하고 다르게 설정\n",
    "if tokenizer.pad_token == tokenizer.eos_token:\n",
    "    tokenizer.add_special_tokens({'pad_token': '<pad>'})\n",
    "\n",
    "inputs = []\n",
    "labels = []\n",
    "\n",
    "for pair in train_data:\n",
    "    input_text = f\"질문: {pair['input']}\"\n",
    "    output_text = f\"답변: {pair['output']}\"\n",
    "    inputs.append(input_text)\n",
    "    labels.append(output_text)\n",
    "\n",
    "# 토크나이즈 및 텐서 변환 (max_length를 명시적으로 설정)\n",
    "encodings = tokenizer(\n",
    "    inputs,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,  # 필요에 따라 조정 가능\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "labels_encodings = tokenizer(\n",
    "    labels,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,  # 필요에 따라 조정 가능\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids = encodings.input_ids\n",
    "attention_mask = encodings.attention_mask\n",
    "labels_ids = labels_encodings.input_ids\n",
    "\n",
    "# 레이블에서 pad_token을 -100으로 마스킹하여 손실 계산에서 제외\n",
    "labels_ids[labels_ids == tokenizer.pad_token_id] = -100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(input_ids, attention_mask, labels_ids)\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "c:\\ProgramData\\anaconda3\\envs\\gnn_snn_torch\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained(\"gogamza/kobart-base-v2\")\n",
    "model.resize_token_embeddings(len(tokenizer))  # pad_token 추가 후 토큰 임베딩 크기 조정\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에포크 1/100 진행 중...\n",
      "에포크 1 완료, 평균 손실 값: 9.3809\n",
      "에포크 2/100 진행 중...\n",
      "에포크 2 완료, 평균 손실 값: 4.3060\n",
      "에포크 3/100 진행 중...\n",
      "에포크 3 완료, 평균 손실 값: 2.3661\n",
      "에포크 4/100 진행 중...\n",
      "에포크 4 완료, 평균 손실 값: 1.6272\n",
      "에포크 5/100 진행 중...\n",
      "에포크 5 완료, 평균 손실 값: 1.1460\n",
      "에포크 6/100 진행 중...\n",
      "에포크 6 완료, 평균 손실 값: 0.8395\n",
      "에포크 7/100 진행 중...\n",
      "에포크 7 완료, 평균 손실 값: 0.6116\n",
      "에포크 8/100 진행 중...\n",
      "에포크 8 완료, 평균 손실 값: 0.4987\n",
      "에포크 9/100 진행 중...\n",
      "에포크 9 완료, 평균 손실 값: 0.3954\n",
      "에포크 10/100 진행 중...\n",
      "에포크 10 완료, 평균 손실 값: 0.3236\n",
      "에포크 11/100 진행 중...\n",
      "에포크 11 완료, 평균 손실 값: 0.2691\n",
      "에포크 12/100 진행 중...\n",
      "에포크 12 완료, 평균 손실 값: 0.2364\n",
      "에포크 13/100 진행 중...\n",
      "에포크 13 완료, 평균 손실 값: 0.1419\n",
      "에포크 14/100 진행 중...\n",
      "에포크 14 완료, 평균 손실 값: 0.1746\n",
      "에포크 15/100 진행 중...\n",
      "에포크 15 완료, 평균 손실 값: 0.1264\n",
      "에포크 16/100 진행 중...\n",
      "에포크 16 완료, 평균 손실 값: 0.0846\n",
      "에포크 17/100 진행 중...\n",
      "에포크 17 완료, 평균 손실 값: 0.0692\n",
      "에포크 18/100 진행 중...\n",
      "에포크 18 완료, 평균 손실 값: 0.0622\n",
      "에포크 19/100 진행 중...\n",
      "에포크 19 완료, 평균 손실 값: 0.0366\n",
      "에포크 20/100 진행 중...\n",
      "에포크 20 완료, 평균 손실 값: 0.0396\n",
      "에포크 21/100 진행 중...\n",
      "에포크 21 완료, 평균 손실 값: 0.0235\n",
      "에포크 22/100 진행 중...\n",
      "에포크 22 완료, 평균 손실 값: 0.0359\n",
      "에포크 23/100 진행 중...\n",
      "에포크 23 완료, 평균 손실 값: 0.0201\n",
      "에포크 24/100 진행 중...\n",
      "에포크 24 완료, 평균 손실 값: 0.0189\n",
      "에포크 25/100 진행 중...\n",
      "에포크 25 완료, 평균 손실 값: 0.0116\n",
      "에포크 26/100 진행 중...\n",
      "에포크 26 완료, 평균 손실 값: 0.0387\n",
      "에포크 27/100 진행 중...\n",
      "에포크 27 완료, 평균 손실 값: 0.0142\n",
      "에포크 28/100 진행 중...\n",
      "에포크 28 완료, 평균 손실 값: 0.0110\n",
      "에포크 29/100 진행 중...\n",
      "에포크 29 완료, 평균 손실 값: 0.0118\n",
      "에포크 30/100 진행 중...\n",
      "에포크 30 완료, 평균 손실 값: 0.0073\n",
      "에포크 31/100 진행 중...\n",
      "에포크 31 완료, 평균 손실 값: 0.0115\n",
      "에포크 32/100 진행 중...\n",
      "에포크 32 완료, 평균 손실 값: 0.0116\n",
      "에포크 33/100 진행 중...\n",
      "에포크 33 완료, 평균 손실 값: 0.0060\n",
      "에포크 34/100 진행 중...\n",
      "에포크 34 완료, 평균 손실 값: 0.0084\n",
      "에포크 35/100 진행 중...\n",
      "에포크 35 완료, 평균 손실 값: 0.0067\n",
      "에포크 36/100 진행 중...\n",
      "에포크 36 완료, 평균 손실 값: 0.0100\n",
      "에포크 37/100 진행 중...\n",
      "에포크 37 완료, 평균 손실 값: 0.0049\n",
      "에포크 38/100 진행 중...\n",
      "에포크 38 완료, 평균 손실 값: 0.0070\n",
      "에포크 39/100 진행 중...\n",
      "에포크 39 완료, 평균 손실 값: 0.0056\n",
      "에포크 40/100 진행 중...\n",
      "에포크 40 완료, 평균 손실 값: 0.0057\n",
      "에포크 41/100 진행 중...\n",
      "에포크 41 완료, 평균 손실 값: 0.0035\n",
      "에포크 42/100 진행 중...\n",
      "에포크 42 완료, 평균 손실 값: 0.0030\n",
      "에포크 43/100 진행 중...\n",
      "에포크 43 완료, 평균 손실 값: 0.0032\n",
      "에포크 44/100 진행 중...\n",
      "에포크 44 완료, 평균 손실 값: 0.0035\n",
      "에포크 45/100 진행 중...\n",
      "에포크 45 완료, 평균 손실 값: 0.0046\n",
      "에포크 46/100 진행 중...\n",
      "에포크 46 완료, 평균 손실 값: 0.0025\n",
      "에포크 47/100 진행 중...\n",
      "에포크 47 완료, 평균 손실 값: 0.0051\n",
      "에포크 48/100 진행 중...\n",
      "에포크 48 완료, 평균 손실 값: 0.0029\n",
      "에포크 49/100 진행 중...\n",
      "에포크 49 완료, 평균 손실 값: 0.0030\n",
      "에포크 50/100 진행 중...\n",
      "에포크 50 완료, 평균 손실 값: 0.0024\n",
      "에포크 51/100 진행 중...\n",
      "에포크 51 완료, 평균 손실 값: 0.0022\n",
      "에포크 52/100 진행 중...\n",
      "에포크 52 완료, 평균 손실 값: 0.0019\n",
      "에포크 53/100 진행 중...\n",
      "에포크 53 완료, 평균 손실 값: 0.0023\n",
      "에포크 54/100 진행 중...\n",
      "에포크 54 완료, 평균 손실 값: 0.0021\n",
      "에포크 55/100 진행 중...\n",
      "에포크 55 완료, 평균 손실 값: 0.0024\n",
      "에포크 56/100 진행 중...\n",
      "에포크 56 완료, 평균 손실 값: 0.0042\n",
      "에포크 57/100 진행 중...\n",
      "에포크 57 완료, 평균 손실 값: 0.0090\n",
      "에포크 58/100 진행 중...\n",
      "에포크 58 완료, 평균 손실 값: 0.0027\n",
      "에포크 59/100 진행 중...\n",
      "에포크 59 완료, 평균 손실 값: 0.0236\n",
      "에포크 60/100 진행 중...\n",
      "에포크 60 완료, 평균 손실 값: 0.0104\n",
      "에포크 61/100 진행 중...\n",
      "에포크 61 완료, 평균 손실 값: 0.0422\n",
      "에포크 62/100 진행 중...\n",
      "에포크 62 완료, 평균 손실 값: 0.0376\n",
      "에포크 63/100 진행 중...\n",
      "에포크 63 완료, 평균 손실 값: 0.0169\n",
      "에포크 64/100 진행 중...\n",
      "에포크 64 완료, 평균 손실 값: 0.0312\n",
      "에포크 65/100 진행 중...\n",
      "에포크 65 완료, 평균 손실 값: 0.0122\n",
      "에포크 66/100 진행 중...\n",
      "에포크 66 완료, 평균 손실 값: 0.0094\n",
      "에포크 67/100 진행 중...\n",
      "에포크 67 완료, 평균 손실 값: 0.0098\n",
      "에포크 68/100 진행 중...\n",
      "에포크 68 완료, 평균 손실 값: 0.0052\n",
      "에포크 69/100 진행 중...\n",
      "에포크 69 완료, 평균 손실 값: 0.0039\n",
      "에포크 70/100 진행 중...\n",
      "에포크 70 완료, 평균 손실 값: 0.0038\n",
      "에포크 71/100 진행 중...\n",
      "에포크 71 완료, 평균 손실 값: 0.0038\n",
      "에포크 72/100 진행 중...\n",
      "에포크 72 완료, 평균 손실 값: 0.0030\n",
      "에포크 73/100 진행 중...\n",
      "에포크 73 완료, 평균 손실 값: 0.0019\n",
      "에포크 74/100 진행 중...\n",
      "에포크 74 완료, 평균 손실 값: 0.0025\n",
      "에포크 75/100 진행 중...\n",
      "에포크 75 완료, 평균 손실 값: 0.0023\n",
      "에포크 76/100 진행 중...\n",
      "에포크 76 완료, 평균 손실 값: 0.0018\n",
      "에포크 77/100 진행 중...\n",
      "에포크 77 완료, 평균 손실 값: 0.0015\n",
      "에포크 78/100 진행 중...\n",
      "에포크 78 완료, 평균 손실 값: 0.0018\n",
      "에포크 79/100 진행 중...\n",
      "에포크 79 완료, 평균 손실 값: 0.0022\n",
      "에포크 80/100 진행 중...\n",
      "에포크 80 완료, 평균 손실 값: 0.0032\n",
      "에포크 81/100 진행 중...\n",
      "에포크 81 완료, 평균 손실 값: 0.0016\n",
      "에포크 82/100 진행 중...\n",
      "에포크 82 완료, 평균 손실 값: 0.0014\n",
      "에포크 83/100 진행 중...\n",
      "에포크 83 완료, 평균 손실 값: 0.0015\n",
      "에포크 84/100 진행 중...\n",
      "에포크 84 완료, 평균 손실 값: 0.0018\n",
      "에포크 85/100 진행 중...\n",
      "에포크 85 완료, 평균 손실 값: 0.0013\n",
      "에포크 86/100 진행 중...\n",
      "에포크 86 완료, 평균 손실 값: 0.0013\n",
      "에포크 87/100 진행 중...\n",
      "에포크 87 완료, 평균 손실 값: 0.0014\n",
      "에포크 88/100 진행 중...\n",
      "에포크 88 완료, 평균 손실 값: 0.0015\n",
      "에포크 89/100 진행 중...\n",
      "에포크 89 완료, 평균 손실 값: 0.0010\n",
      "에포크 90/100 진행 중...\n",
      "에포크 90 완료, 평균 손실 값: 0.0013\n",
      "에포크 91/100 진행 중...\n",
      "에포크 91 완료, 평균 손실 값: 0.0010\n",
      "에포크 92/100 진행 중...\n",
      "에포크 92 완료, 평균 손실 값: 0.0016\n",
      "에포크 93/100 진행 중...\n",
      "에포크 93 완료, 평균 손실 값: 0.0010\n",
      "에포크 94/100 진행 중...\n",
      "에포크 94 완료, 평균 손실 값: 0.0009\n",
      "에포크 95/100 진행 중...\n",
      "에포크 95 완료, 평균 손실 값: 0.0011\n",
      "에포크 96/100 진행 중...\n",
      "에포크 96 완료, 평균 손실 값: 0.0013\n",
      "에포크 97/100 진행 중...\n",
      "에포크 97 완료, 평균 손실 값: 0.0010\n",
      "에포크 98/100 진행 중...\n",
      "에포크 98 완료, 평균 손실 값: 0.0008\n",
      "에포크 99/100 진행 중...\n",
      "에포크 99 완료, 평균 손실 값: 0.0008\n",
      "에포크 100/100 진행 중...\n",
      "에포크 100 완료, 평균 손실 값: 0.0010\n"
     ]
    }
   ],
   "source": [
    "epochs = 100  # 에포크 수 조정 가능\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"에포크 {epoch+1}/{epochs} 진행 중...\")\n",
    "    total_loss = 0\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids_batch = batch[0].to(device)\n",
    "        attention_mask_batch = batch[1].to(device)\n",
    "        labels_batch = batch[2].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids_batch,\n",
    "            attention_mask=attention_mask_batch,\n",
    "            labels=labels_batch\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"에포크 {epoch+1} 완료, 평균 손실 값: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./food_chatbot_model\\\\tokenizer_config.json',\n",
       " './food_chatbot_model\\\\special_tokens_map.json',\n",
       " './food_chatbot_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./food_chatbot_model\")\n",
    "tokenizer.save_pretrained(\"./food_chatbot_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./food_chatbot_model\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"./food_chatbot_model\")\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(input_text, mode='few-shot'):\n",
    "    if mode == 'zero-shot':\n",
    "        prompt = f\"질문: {input_text}\\n답변: \"\n",
    "    elif mode == 'few-shot':\n",
    "        # Few-Shot을 위해 몇 가지 예시를 추가\n",
    "        few_shot_examples = (\n",
    "            \"질문: 배가 고픈데 뭐 먹을까?\\n답변: 한식은 어때요? 따뜻한 국밥이 좋을 것 같아요.\\n\"\n",
    "            \"질문: 점심 추천해줘\\n답변: 가벼운 샐러드나 샌드위치는 어떠세요?\\n\"\n",
    "            \"질문: 저녁 뭐 먹을지 고민돼\\n답변: 맛있는 파스타나 스테이크는 어떠신가요?\\n\"\n",
    "        )\n",
    "        prompt = f\"{few_shot_examples}질문: {input_text}\\n답변: \"\n",
    "    else:\n",
    "        prompt = f\"질문: {input_text}\\n답변: \"\n",
    "\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt', truncation=True, max_length=128).to(device)\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            max_length=128,  # 적절한 max_length 설정\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.92,\n",
    "            temperature=0.6,\n",
    "            repetition_penalty=1.2,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            use_cache=True\n",
    "        )\n",
    "    output = tokenizer.decode(\n",
    "        output_ids[0],\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=True  # 경고를 제거하기 위해 추가\n",
    "    )\n",
    "    \n",
    "    # 디버깅을 위한 출력\n",
    "    # print(f\"DEBUG: Generated Output: {output}\")\n",
    "\n",
    "    # 답변 부분만 추출 (마지막 '답변:' 이후 텍스트)\n",
    "    if \"답변:\" in output:\n",
    "        response = output.rsplit(\"답변:\", 1)[-1].strip()\n",
    "    else:\n",
    "        response = \"죄송합니다. 이해하지 못했어요.\"\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "음식 추천 챗봇입니다. 종료하려면 '종료'를 입력하세요.\n",
      "챗봇: 가벼운 샐러드나 샌드위치는 어떠세요? 따뜻한 국밥이 좋을 것 같아요. 따뜻한 국밥이나 샌드위치는 어떠세요? 따뜻한 국밥이 좋겠어요.\n",
      "챗봇: 시원한 냉면이나 팥빙수를 드셔보세요.\n",
      "챗봇: 시원한 냉면이나 팥빙수를 드셔보세요.\n",
      "챗봇: 대화를 종료합니다. 좋은 하루 되세요!\n"
     ]
    }
   ],
   "source": [
    "print(\"음식 추천 챗봇입니다. 종료하려면 '종료'를 입력하세요.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"사용자: \")\n",
    "    if user_input.strip().lower() == \"종료\":\n",
    "        print(\"챗봇: 대화를 종료합니다. 좋은 하루 되세요!\")\n",
    "        break\n",
    "    # mode를 'zero-shot' 또는 'few-shot'으로 설정\n",
    "    response = generate_response(user_input, mode='zero-shot')\n",
    "    print(f\"챗봇: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_snn_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
